{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials,messaging\n",
    "from firebase_admin import firestore\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = credentials.Certificate(\"esp32-9e776-firebase-adminsdk-24lzj-b0eb618d5a.json\")\n",
    "app  = firebase_admin.initialize_app(cred)\n",
    "\n",
    "def sendPush(title, msg, registration_token, dataObject=None):\n",
    "    # See documentation on defining a message payload.\n",
    "    message = messaging.MulticastMessage(\n",
    "        notification=messaging.Notification(\n",
    "            title=title,\n",
    "            body=msg\n",
    "        ),\n",
    "        data=dataObject,\n",
    "        tokens=registration_token,\n",
    "    )\n",
    "\n",
    "    response = messaging.send_multicast(message)\n",
    "    print('Successfully sent message:', response)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Token():\n",
    "    db = firestore.client()\n",
    "    doc = db.collection('tokens').get()\n",
    "    tokens = []\n",
    "    for i in doc:\n",
    "        tokens.append(i.to_dict()['fcmToken'])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_system():\n",
    "    global door_unlocked\n",
    "    known_faces_dir = 'PROJECT/p1'\n",
    "    known_face_encodings, known_face_names = load_known_faces(known_faces_dir)\n",
    "\n",
    "    # Initialize MediaPipe Face Detection\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Dictionary to track the last recognized time\n",
    "    last_recognized_time = {name: datetime.min for name in known_face_names}\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "            model_selection=1, min_detection_confidence=0.5) as face_detection:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert the frame to RGB\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(rgb_frame)\n",
    "\n",
    "            face_detected = False\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    # Get bounding box\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, _ = frame.shape\n",
    "                    x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                                int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                    # Draw bounding box\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "                    # Extract face ROI\n",
    "                    face_roi = np.ascontiguousarray(rgb_frame[y:y + h, x:x + w])\n",
    "\n",
    "                    # Recognize the face using face_recognition\n",
    "                    face_encodings = face_recognition.face_encodings(face_roi)\n",
    "                    if face_encodings:\n",
    "                        face_encoding = face_encodings[0]\n",
    "                        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                        best_match_index = np.argmin(face_distances)\n",
    "                        current_time = datetime.now()\n",
    "                        if matches[best_match_index] and (current_time - last_recognized_time[known_face_names[best_match_index]] > timedelta(minutes=1)):\n",
    "                            name = known_face_names[best_match_index]\n",
    "                            last_recognized_time[name] = current_time\n",
    "                            tokens = get_Token()\n",
    "                            sendPush(\"Known Person Detected\", f\"{name} Detected\", tokens)\n",
    "                            save_recognized_face(face_roi, name)\n",
    "                            db = firestore.client()\n",
    "                            doc = db.collection('flags').document('lock').set({'yes':False})\n",
    "                            print(\"Face detected. Pausing for one minute.\")\n",
    "                            door_unlocked=1\n",
    "                            \n",
    "                        else:\n",
    "                            name = \"Unknown\"\n",
    "                            tokens = get_Token()\n",
    "                            sendPush(\"Unknown Person Detected\", \"Unknown Person Detected\", tokens)\n",
    "                            save_recognized_face(face_roi, name)\n",
    "                            print(\"Face detected. Pausing for one minute.\")\n",
    "                            time.sleep(60)\n",
    "                        \n",
    "                        # Draw name\n",
    "                        cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "                        while(door_unlocked):\n",
    "                                print(\"Door Opened\")\n",
    "                                door_unlocked = int(input('Enter State: '))\n",
    "\n",
    "\n",
    "            cv2.imshow('MediaPipe Face Recognition', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "\n",
    "    # Release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\College\\4TH SEMESTER\\INTRODUCTION TO COMMUNICTION AND IOT\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully sent message: <firebase_admin.messaging.BatchResponse object at 0x000001727FBA7990>\n",
      "C:/Users/nithi/Documents/IoT/p1_20240528_011237.jpg\n",
      "Door Opened\n",
      "Enter State: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "thread1 = threading.Thread(target=camera_system)\n",
    "thread1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes': True}\n"
     ]
    }
   ],
   "source": [
    "def door_lock_change():\n",
    "    global door_unlocked\n",
    "    db = firestore.client()\n",
    "\n",
    "    doc = db.collection('flags').document('lock').get()\n",
    "\n",
    "    print(doc.to_dict())\n",
    "\n",
    "door_lock_change()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
